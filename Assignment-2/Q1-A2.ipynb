{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "memory = '100g'\n",
    "pyspark_submit_args = '--packages org.postgresql:postgresql:42.2.9 pyspark-shell' + ' --driver-memory ' + memory + ' pyspark-shell ' + '--num-executors 3'\n",
    "import time\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('BDA_A2').master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/assignment1\") \\\n",
    "    .option(\"dbtable\", \"GHTORRENT_RECORDS\") \\\n",
    "    .option('user', 'postgres') \\\n",
    "    .option('password', 'admin') \\\n",
    "    .option('driver', 'org.postgresql.Driver') \\\n",
    "    .load()\n",
    "\n",
    "df2 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/assignment1\") \\\n",
    "    .option(\"dbtable\", \"IMPORTANT_REPOS\") \\\n",
    "    .option('user', 'postgres') \\\n",
    "    .option('password', 'admin') \\\n",
    "    .option('driver', 'org.postgresql.Driver') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table1\n",
      "root\n",
      " |-- logging_level: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- downloader_id: string (nullable = true)\n",
      " |-- retrieval_stage: string (nullable = true)\n",
      " |-- request_status: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- access_key: string (nullable = true)\n",
      "\n",
      "Table2\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- owner_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- forked_from: string (nullable = true)\n",
      " |-- deleted: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Table1\")\n",
    "df1.printSchema()\n",
    "\n",
    "print(\"Table2\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView('GHTORRENT_RECORDS')\n",
    "df2.createOrReplaceTempView('IMPORTANT_REPOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records does the table contain?\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 9669634|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"SELECT COUNT(*) FROM GHTORRENT_RECORDS\"\n",
    "result2 = spark.sql(query2)\n",
    "print(\"How many records does the table contain?\") \n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count the number of WARNing messages.\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  132158|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"SELECT COUNT(*) FROM GHTORRENT_RECORDS WHERE LOGGING_LEVEL='WARN'\"\n",
    "result3 = spark.sql(query3)\n",
    "print(\"Count the number of WARNing messages.\")\n",
    "result3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many repositories were processed in total?\n",
      "+-------------------+\n",
      "|count(DISTINCT URL)|\n",
      "+-------------------+\n",
      "|              78369|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 78588\n",
    "query4 = '''SELECT COUNT(DISTINCT URL) \n",
    "               FROM GHTORRENT_RECORDS \n",
    "               WHERE RETRIEVAL_STAGE = 'api_client' AND URL != 'NULL' '''\n",
    "result4 = spark.sql(query4)\n",
    "print(\"How many repositories were processed in total?\")\n",
    "result4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+\n",
      "|count(RETRIEVAL_STAGE)|DOWNLOADER_ID|\n",
      "+----------------------+-------------+\n",
      "|                 85528|           13|\n",
      "|                 19046|            4|\n",
      "|                 18948|           18|\n",
      "|                 18926|           10|\n",
      "|                 18911|           40|\n",
      "|                 18616|           39|\n",
      "|                 18614|           38|\n",
      "|                 18604|           47|\n",
      "|                 18463|            1|\n",
      "|                 18452|           24|\n",
      "+----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query5 = \"\"\"SELECT COUNT(RETRIEVAL_STAGE), DOWNLOADER_ID\n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE RETRIEVAL_STAGE='api_client' AND URL != 'NULL'\n",
    "            GROUP BY DOWNLOADER_ID\n",
    "            ORDER BY COUNT(RETRIEVAL_STAGE) DESC \n",
    "            LIMIT 10\"\"\"\n",
    "result5 = spark.sql(query5)\n",
    "result5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+\n",
      "|count(RETRIEVAL_STAGE)|DOWNLOADER_ID|\n",
      "+----------------------+-------------+\n",
      "|                 79623|           13|\n",
      "|                  1378|           21|\n",
      "|                  1134|           40|\n",
      "|                   368|           18|\n",
      "|                   357|           42|\n",
      "|                   356|            9|\n",
      "|                   352|            4|\n",
      "|                   342|           25|\n",
      "|                   333|           22|\n",
      "|                   332|            6|\n",
      "+----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [(79623, '13'), (1378, '21'), (1134, '40'), (368, '18'), (357, '42'), (356, '9'), (352, '4'), (342, '25'), (333, '22'), (332, '6')]\n",
    "query6 = \"\"\"SELECT COUNT(RETRIEVAL_STAGE), DOWNLOADER_ID\n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE RETRIEVAL_STAGE='api_client' AND REQUEST_STATUS='Failed'\n",
    "            GROUP BY DOWNLOADER_ID\n",
    "            ORDER BY COUNT(RETRIEVAL_STAGE) DESC \n",
    "            LIMIT 10\"\"\"\n",
    "result6 = spark.sql(query6)\n",
    "result6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(2662487, '10')]\n",
    "# Takes a lot of time to run\n",
    "query7 = \"\"\"\n",
    "            SELECT NEWT.TS\n",
    "            FROM (SELECT LOGGING_LEVEL, SUBSTRING(TIMESTAMP, 12, 2) AS TS, DOWNLOADER_ID, RETRIEVAL_STAGE, REQUEST_STATUS, URL, ACCESS_KEY\n",
    "                  FROM GHTORRENT_RECORDS) AS NEWT\n",
    "            GROUP BY NEWT.TS\n",
    "            ORDER BY COUNT(NEWT.TS) DESC\n",
    "            LIMIT 1\n",
    "            \"\"\"\n",
    "result7 = spark.sql(query7)\n",
    "result7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 URL|\n",
      "+--------------------+\n",
      "|https://api.githu...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [('https://api.github.com/repos/greatfakeman/Tabchi', 79539)]\n",
    "query8 = '''\n",
    "        SELECT  URL\n",
    "        FROM GHTORRENT_RECORDS\n",
    "        WHERE URL != 'NULL'\n",
    "        GROUP BY URL\n",
    "        ORDER BY COUNT(URL) DESC\n",
    "        LIMIT 1'''\n",
    "result8 = spark.sql(query8)\n",
    "result8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "| ACCESS_KEY|key_count|\n",
      "+-----------+---------+\n",
      "|ac6168f8776|    79623|\n",
      "|46f11b5791b|     1340|\n",
      "|9115020fb01|     1134|\n",
      "|c1240f63b5b|      371|\n",
      "|2776f3ba0a5|      368|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [('ac6168f8776', 79623), ('46f11b5791b', 1340), ('9115020fb01', 1134), ('c1240f63b5b', 371), ('2776f3ba0a5', 368)]\n",
    "query9 = '''\n",
    "        SELECT  ACCESS_KEY, COUNT(ACCESS_KEY) AS key_count\n",
    "        FROM GHTORRENT_RECORDS\n",
    "        WHERE ACCESS_KEY != 'NULL'\n",
    "        GROUP BY ACCESS_KEY\n",
    "        ORDER BY key_count DESC\n",
    "        LIMIT 5'''\n",
    "result9 = spark.sql(query9)\n",
    "result9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2 Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records does the IMPORTANT_REPOS table contain?\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1435|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query10 = \"SELECT COUNT(*) FROM IMPORTANT_REPOS\"\n",
    "result10 = spark.sql(query10)\n",
    "print(\"How many records does the IMPORTANT_REPOS table contain?\")\n",
    "result10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records in the log file refer to entries in the interesting file?\n",
      "+----------+\n",
      "|count(URL)|\n",
      "+----------+\n",
      "|    158348|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query11 = '''\n",
    "            SELECT COUNT(ir.URL)\n",
    "            FROM GHTORRENT_RECORDS gt\n",
    "            INNER JOIN IMPORTANT_REPOS ir\n",
    "                ON gt.URL != 'NULL' AND gt.URL=ir.URL\n",
    "            '''\n",
    "result11 = spark.sql(query11)\n",
    "print(\"How many records in the log file refer to entries in the interesting file?\")\n",
    "result11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which of the interesting repositories has the most failed API calls?\n",
      "+--------------------+----------+\n",
      "|                 URL|count(URL)|\n",
      "+--------------------+----------+\n",
      "|https://api.githu...|         5|\n",
      "|https://api.githu...|         3|\n",
      "|https://api.githu...|         3|\n",
      "|https://api.githu...|         2|\n",
      "|https://api.githu...|         2|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query12 = '''\n",
    "            SELECT ir.URL, COUNT(ir.URL)\n",
    "            FROM GHTORRENT_RECORDS gt\n",
    "            INNER JOIN IMPORTANT_REPOS ir\n",
    "            ON gt.URL != 'NULL' AND gt.URL=ir.URL AND gt.REQUEST_STATUS = 'Failed' \n",
    "            GROUP BY ir.URL\n",
    "            ORDER BY COUNT(ir.URL) DESC\n",
    "            LIMIT 5'''\n",
    "result12 = spark.sql(query12)\n",
    "print(\"Which of the interesting repositories has the most failed API calls?\")\n",
    "result12.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeTaken: 0.24361324310302734 ms\n"
     ]
    }
   ],
   "source": [
    "query10 = '''\n",
    "            SELECT COUNT(DISTINCT URL) \n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE DOWNLOADER_ID = '22' AND URL != 'NULL'\n",
    "            '''\n",
    "\n",
    "start_time = time.time()\n",
    "spark.sql(query10)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"TimeTaken: {} ms\".format(end_time-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeTaken: 0.3787837028503418 ms\n"
     ]
    }
   ],
   "source": [
    "query11 = '''\n",
    "            SELECT COUNT(DISTINCT URL) \n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE DOWNLOADER_ID = '22' AND URL != 'NULL'\n",
    "            '''\n",
    "\n",
    "start_time = time.time()\n",
    "spark.sql(query11)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"TimeTaken: {} ms\".format(end_time-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
