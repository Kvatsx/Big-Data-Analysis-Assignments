{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.3.1 pyspark-shell'\n",
    "os.environ['SPARK_HOME'] = './spark-2.4.4-bin-hadoop2.7'\n",
    "os.environ['PYSPARK_PYTHON']='/usr/lib/python3.5'\n",
    "# !export SPARK_HOME=./spark-2.4.4-bin-hadoop2.7\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import time\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- access_key: string (nullable = true)\n",
      " |-- downloader_id: string (nullable = true)\n",
      " |-- logging_level: string (nullable = true)\n",
      " |-- request_status: string (nullable = true)\n",
      " |-- retrieval_stage: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('BDA_A2_Mongodb').master('local') \\\n",
    "        .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1:27017/assignment2.table1\") \\\n",
    "        .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1:27017/assignment2.table1\") \\\n",
    "        .config('spark jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.3.1') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "df.printSchema()\n",
    "df.createOrReplaceTempView('GHTORRENT_RECORDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- deleted: string (nullable = true)\n",
      " |-- forked_from: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- owner_id: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark2 = SparkSession.builder.appName('BDA_A2_Mongodb').master('local') \\\n",
    "        .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1:27017/assignment2.table2\") \\\n",
    "        .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1:27017/assignment2.table2\") \\\n",
    "        .config('spark jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.3.1') \\\n",
    "        .getOrCreate()\n",
    "df2 = spark2.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "df2.printSchema()\n",
    "df2.createOrReplaceTempView('IMPORTANT_REPOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- access_key: string (nullable = true)\n",
      " |-- downloader_id: string (nullable = true)\n",
      " |-- logging_level: string (nullable = true)\n",
      " |-- request_status: string (nullable = true)\n",
      " |-- retrieval_stage: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- deleted: string (nullable = true)\n",
      " |-- forked_from: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- owner_id: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  132158|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"\"\"SELECT COUNT(*) FROM GHTORRENT_RECORDS WHERE LOGGING_LEVEL='WARN'\"\"\"\n",
    "result3 = spark.sql(query3)\n",
    "# print(\"Count the number of WARNing messages.\")\n",
    "result3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = '''SELECT COUNT(DISTINCT URL) \n",
    "               FROM GHTORRENT_RECORDS \n",
    "               WHERE RETRIEVAL_STAGE = 'api_client' AND URL != 'NULL' '''\n",
    "result4 = spark.sql(query4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT URL)|\n",
      "+-------------------+\n",
      "|              78369|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+\n",
      "|count(RETRIEVAL_STAGE)|DOWNLOADER_ID|\n",
      "+----------------------+-------------+\n",
      "|                 85528|           13|\n",
      "|                 19046|            4|\n",
      "|                 18948|           18|\n",
      "|                 18926|           10|\n",
      "|                 18911|           40|\n",
      "|                 18616|           39|\n",
      "|                 18614|           38|\n",
      "|                 18604|           47|\n",
      "|                 18463|            1|\n",
      "|                 18452|           24|\n",
      "+----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query5 = \"\"\"SELECT COUNT(RETRIEVAL_STAGE), DOWNLOADER_ID\n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE RETRIEVAL_STAGE='api_client' AND URL != 'NULL'\n",
    "            GROUP BY DOWNLOADER_ID\n",
    "            ORDER BY COUNT(RETRIEVAL_STAGE) DESC \n",
    "            LIMIT 10\"\"\"\n",
    "result5 = spark.sql(query5)\n",
    "result5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "myclient = MongoClient('localhost', 27017)\n",
    "myData = myclient['assignment2']\n",
    "\n",
    "Table1 = myData['table1']\n",
    "Table1.create_index('DOWNLOADER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT URL)|\n",
      "+-------------------+\n",
      "|               4390|\n",
      "+-------------------+\n",
      "\n",
      "TimeTaken: 0.5066001415252686 ms\n"
     ]
    }
   ],
   "source": [
    "query10 = '''\n",
    "            SELECT COUNT(DISTINCT URL) \n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE DOWNLOADER_ID = '22' AND URL != 'NULL' '''\n",
    "\n",
    "start_time = time.time()\n",
    "result10 = spark.sql(query10)\n",
    "end_time = time.time()\n",
    "\n",
    "result10.show()\n",
    "print(\"TimeTaken: {} ms\".format(end_time-start_time))\n",
    "# print(rows[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table1.drop_index('DOWNLOADER_ID_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT URL)|\n",
      "+-------------------+\n",
      "|               4390|\n",
      "+-------------------+\n",
      "\n",
      "TimeTaken: 1.1038885116577148 ms\n"
     ]
    }
   ],
   "source": [
    "query10 = '''\n",
    "            SELECT COUNT(DISTINCT URL) \n",
    "            FROM GHTORRENT_RECORDS \n",
    "            WHERE DOWNLOADER_ID = '22' AND URL != 'NULL' '''\n",
    "\n",
    "start_time = time.time()\n",
    "result10 = spark.sql(query10)\n",
    "end_time = time.time()\n",
    "\n",
    "result10.show()\n",
    "print(\"TimeTaken: {} ms\".format(end_time-start_time))\n",
    "# print(rows[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
